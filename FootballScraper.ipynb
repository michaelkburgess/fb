{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ef1bfeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files loaded successfully!\n",
      "== Home: Everton | Away: Newcastle United ==\n",
      "--------------------------------------------\n",
      "               Team  Win Chance (%)  Odds\n",
      "0           Everton           12.00  8.33\n",
      "1  Newcastle United           63.00  1.59\n",
      "2              Draw           24.00  4.17\n",
      "3             Total            0.99     -\n",
      "--------------------------------------------\n",
      "\n",
      "== Home: Tottenham Hotspur | Away: West Ham United ==\n",
      "-----------------------------------------------------\n",
      "                Team  Win Chance (%)  Odds\n",
      "0  Tottenham Hotspur           26.00  3.85\n",
      "1    West Ham United           50.00   2.0\n",
      "2               Draw           23.00  4.35\n",
      "3              Total            0.99     -\n",
      "-----------------------------------------------------\n",
      "\n",
      "== Home: Crystal Palace | Away: Liverpool ==\n",
      "--------------------------------------------\n",
      "             Team  Win Chance (%)  Odds\n",
      "0  Crystal Palace           18.00  5.56\n",
      "1       Liverpool           57.00  1.75\n",
      "2            Draw           24.00  4.17\n",
      "3           Total            0.99     -\n",
      "--------------------------------------------\n",
      "\n",
      "== Home: Brighton & Hove Albion | Away: Burnley ==\n",
      "--------------------------------------------------\n",
      "                     Team  Win Chance (%)  Odds\n",
      "0  Brighton & Hove Albion           37.00   2.7\n",
      "1                 Burnley           31.00  3.23\n",
      "2                    Draw           33.00  3.03\n",
      "3                   Total            1.01     -\n",
      "--------------------------------------------------\n",
      "\n",
      "== Home: Bournemouth | Away: AFC Bournemouth ==\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikeb\\AppData\\Local\\Temp\\ipykernel_22840\\3161346289.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  result = float(atk) * float(dfnce) * float(avg_away_xG)\n",
      "C:\\Users\\mikeb\\AppData\\Local\\Temp\\ipykernel_22840\\3161346289.py:17: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  result = float(atk) * float(dfnce) * float(avg_away_xG)\n",
      "C:\\Users\\mikeb\\AppData\\Local\\Temp\\ipykernel_22840\\3161346289.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  result = float(atk) * float(dfnce) * float(avg_away_xG)\n",
      "C:\\Users\\mikeb\\AppData\\Local\\Temp\\ipykernel_22840\\3161346289.py:17: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  result = float(atk) * float(dfnce) * float(avg_away_xG)\n",
      "C:\\Users\\mikeb\\AppData\\Local\\Temp\\ipykernel_22840\\3161346289.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  result = float(atk) * float(dfnce) * float(avg_away_xG)\n",
      "C:\\Users\\mikeb\\AppData\\Local\\Temp\\ipykernel_22840\\3161346289.py:17: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  result = float(atk) * float(dfnce) * float(avg_away_xG)\n",
      "C:\\Users\\mikeb\\AppData\\Local\\Temp\\ipykernel_22840\\3161346289.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  result = float(atk) * float(dfnce) * float(avg_away_xG)\n",
      "C:\\Users\\mikeb\\AppData\\Local\\Temp\\ipykernel_22840\\3161346289.py:17: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  result = float(atk) * float(dfnce) * float(avg_away_xG)\n",
      "C:\\Users\\mikeb\\AppData\\Local\\Temp\\ipykernel_22840\\3161346289.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  result = float(atk) * float(dfnce) * float(avg_away_xG)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot convert the series to <class 'float'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 59\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(title)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m#try:\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m home, away \u001b[38;5;241m=\u001b[39m \u001b[43mcompareTeams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhomes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maways\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteam_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhome_atk_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maway_atk_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m probs \u001b[38;5;241m=\u001b[39m getPoisson(home, away)\n\u001b[0;32m     61\u001b[0m summarise(probs, homes[i], aways[i])\n",
      "Cell \u001b[1;32mIn[20], line 6\u001b[0m, in \u001b[0;36mcompareTeams\u001b[1;34m(home_team, away_team, stats, avg_home_xG, avg_away_xG)\u001b[0m\n\u001b[0;32m      4\u001b[0m atk \u001b[38;5;241m=\u001b[39m stats[stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSquad\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m home_team][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maway_atk_str\u001b[39m\u001b[38;5;124m\"\u001b[39m] \n\u001b[0;32m      5\u001b[0m dfnce \u001b[38;5;241m=\u001b[39m stats[stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSquad\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m away_team][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhome_def_str\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(atk) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdfnce\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mfloat\u001b[39m(avg_away_xG)\n\u001b[0;32m      8\u001b[0m home_probs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m6\u001b[39m):   \n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:230\u001b[0m, in \u001b[0;36m_coerce_method.<locals>.wrapper\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    222\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconverter\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on a single element Series is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will raise a TypeError in the future. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    228\u001b[0m     )\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m converter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m--> 230\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot convert the series to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconverter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot convert the series to <class 'float'>"
     ]
    }
   ],
   "source": [
    "## MIKE - run all the cells below this one, then run this cell.\n",
    "\n",
    "#Configuration\n",
    "league = \"EPL\"\n",
    "\n",
    "year = 2024\n",
    "\n",
    "num_to_check = 10\n",
    "\n",
    "# Get today's date\n",
    "todays_date = datetime.now().date().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# File names\n",
    "lg_table_file = \"lg_table_\" + todays_date + \".csv\"\n",
    "match_table_file = \"match_table_\" + todays_date + \".csv\"\n",
    "\n",
    "lg_table = pd.DataFrame()\n",
    "match_table = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    # Try reading the CSV files\n",
    "    lg_table = pd.read_csv(lg_table_file)\n",
    "    match_table = pd.read_csv(match_table_file)\n",
    "\n",
    "    print(\"Files loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    # If the files do not exist, handle the exception here\n",
    "    print(\"CSV file(s) not found for today's date:\", todays_date)\n",
    "    # You can create new DataFrames or perform any other necessary action in case of file absence\n",
    "    \n",
    "\n",
    "\n",
    "if(match_table.empty or lg_table.empty):\n",
    "    lg_table, match_table = scrape_league_and_matches(league, year)\n",
    "    match_table.to_csv(lg_table_file, index=False)\n",
    "    lg_table.to_csv(match_table_file, index=False)\n",
    "\n",
    "\n",
    "    \n",
    "away_averages, home_averages = get_team_averages(lg_table)\n",
    "merged = merge_lg_and_match_tables(match_table, home_averages, away_averages)\n",
    "\n",
    "#Derive league xg and xGA's for home/away (league strength values)\n",
    "home_atk_str = merged[\"Home xG\"].mean()\n",
    "away_atk_str = merged[\"Away xG\"].mean()\n",
    "home_def_str = merged[\"Home xGA\"].mean()\n",
    "away_def_str = merged[\"Away xGA\"].mean()\n",
    "    \n",
    "team_stats = get_team_stats(merged, home_atk_str, away_atk_str, home_def_str, away_def_str)\n",
    "homes, aways = get_next_matches(num_to_check)\n",
    "\n",
    "homes, aways = clean_names(homes, aways)\n",
    "\n",
    "for i in range(0, len(homes)):\n",
    "    title = \"== Home: \" + homes[i] + \" | Away: \" + aways[i] + \" ==\" \n",
    "    print(title)\n",
    "    print(\"\"+\"-\"*len(title)+\"\")\n",
    "    #try:\n",
    "    home, away = compareTeams(homes[i], aways[i], team_stats, home_atk_str, away_atk_str)\n",
    "    probs = getPoisson(home, away)\n",
    "    summarise(probs, homes[i], aways[i])\n",
    "    #except IndexError:\n",
    "        #print(\"\\nSkipping, as team name not possible.\\n\")\n",
    "        \n",
    "    \n",
    "    print(\"\"+\"-\"*len(title)+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909e9df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ScraperFC as sfc\n",
    "import traceback2 as traceback\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "import requests\n",
    "from scipy.stats import poisson\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3192be6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_names(homes, aways):\n",
    "    \n",
    "    for index, squad in enumerate(homes):\n",
    "        if \"Bournemouth\" in squad:\n",
    "            homes[index] = \"Bournemouth\"\n",
    "    \n",
    "    for index, squad in enumerate(aways):\n",
    "        if \"Bournemouth\" in squad:\n",
    "            homes[index] = \"Bournemouth\"\n",
    "        \n",
    "    return homes, aways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b173156",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.football-data.org/client/register\n",
    "def get_next_matches(num):\n",
    "    # Replace 'YOUR_API_KEY' with your actual API key if required by the Premier League API\n",
    "    api_key = '0ea7a91de7094131b0d1cd0e6753b21a'\n",
    "    url = f'https://api.football-data.org/v2/competitions/PL/matches?status=SCHEDULED&limit=10'\n",
    "\n",
    "    headers = {\n",
    "        'X-Auth-Token': api_key  # Add your API key here if required\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "\n",
    "        matches = []\n",
    "        for match in data['matches']:\n",
    "            home_team = match['homeTeam']['name'].replace(\" FC\", \"\")\n",
    "            away_team = match['awayTeam']['name'].replace(\" FC\", \"\")\n",
    "            match_date = match['utcDate']\n",
    "            matches.append({'Home Team': home_team, 'Away Team': away_team, 'Date': match_date})\n",
    "\n",
    "        # Create a DataFrame\n",
    "        df = pd.DataFrame(matches)\n",
    "\n",
    "        # Convert 'Date' column to datetime\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "        # Sort by the 'Date' column (most recent matches first)\n",
    "        df = df.sort_values(by='Date', ascending=True)\n",
    "        selection = df.head(num)\n",
    "        home_team = list(selection[\"Home Team\"])\n",
    "        away_team = list(selection[\"Away Team\"])\n",
    "        \n",
    "\n",
    "        return home_team, away_team\n",
    "    \n",
    "    else:\n",
    "        print(\"Failed to fetch data. Status code:\", response.status_code)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "291eba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the FBRef scraper\n",
    "def scrape_league_and_matches(league, year):\n",
    "    scraper = sfc.FBRef()\n",
    "\n",
    "    try:\n",
    "        # Scrape the League table\n",
    "        lg_table = scraper.scrape_league_table(year=year, league=league)\n",
    "\n",
    "        # clean league table columns\n",
    "        lg_table.drop(columns=[\"Goalkeeper\", \"Attendance\", \"Top Team Scorer\", \"Notes\"], inplace=True)\n",
    "\n",
    "        # Scrape the Match table\n",
    "        match_table = scraper.scrape_matches(year, league, save=False)\n",
    "        # Define unneccesary columns to be removed\n",
    "        rm_cols = ['Home Team ID',\n",
    "               'Away Team ID', 'Home Formation', 'Away Formation', 'Home Player Stats',\n",
    "               'Away Player Stats', \"Away Ast\", \"Home Ast\", \"Home xAG\", \"Away xAG\", \"Home npxG\", \"Away npxG\"]\n",
    "        #remove\n",
    "        match_table.drop(columns=rm_cols, inplace=True)\n",
    "   \n",
    "    except:\n",
    "        # Catch and print any exceptions. This allows us to still close the\n",
    "        # scraper below, even if an exception occurs.\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        # It's important to close the scraper when you're done with it. Otherwise,\n",
    "        # you'll have a bunch of webdrivers open and running in the background.\n",
    "        scraper.close()\n",
    "    return lg_table, match_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d5311e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_averages(lg_table):\n",
    "    #Get unique team names\n",
    "    away_teams = lg_table[\"Away Team\"].unique()\n",
    "    home_teams = lg_table[\"Home Team\"].unique()\n",
    "    away_averages = pd.DataFrame()\n",
    "    home_averages = pd.DataFrame()\n",
    "\n",
    "    #For each away team, get the last 5 match results from match table, getting the mean GA, GF, xGA xG values.\n",
    "    # Store as dataframe away_averages\n",
    "    for team in away_teams:\n",
    "        team_table = lg_table[lg_table[\"Away Team\"] == team].tail(5)\n",
    "        team_table.rename(columns={\"Home xG\" : \"Away xGA\"}, inplace=True)\n",
    "        team_table.rename(columns={\"Home Goals\" : \"Away GA\"}, inplace=True)\n",
    "        team_table.rename(columns={\"Away Goals\" : \"Away GF\"}, inplace=True)\n",
    "\n",
    "        new_data = {\n",
    "            \"Squad\": [team],\n",
    "            \"Away GA\": [team_table[\"Away GA\"].mean()],\n",
    "            \"Away GF\": [team_table[\"Away GF\"].mean()],\n",
    "            \"Away xGA\": [team_table[\"Away xGA\"].mean()],\n",
    "            \"Away xG\": [team_table[\"Away xG\"].mean()]\n",
    "        }\n",
    "        new_df = pd.DataFrame(new_data)\n",
    "       \n",
    "        away_averages = pd.concat([away_averages, new_df], ignore_index=True)\n",
    "\n",
    "\n",
    "    #For each home team, get the last 5 match results from match table, getting the mean GA, GF, xGA xG values.\n",
    "    # Store as dataframe home_averages   \n",
    "    for team in home_teams:\n",
    "        team_table = lg_table[lg_table[\"Home Team\"] == team].tail(5)\n",
    "\n",
    "        team_table.rename(columns={\"Away xG\" : \"Home xGA\"}, inplace=True)\n",
    "        team_table.rename(columns={\"Away Goals\" : \"Home GA\"}, inplace=True)\n",
    "        team_table.rename(columns={\"Home Goals\" : \"Home GF\"}, inplace=True)\n",
    "\n",
    "        new_data = {\n",
    "            \"Squad\": [team],\n",
    "            \"Home GA\": [team_table[\"Home GA\"].mean()],\n",
    "            \"Home GF\": [team_table[\"Home GF\"].mean()],\n",
    "            \"Home xGA\": [team_table[\"Home xGA\"].mean()],\n",
    "            \"Home xG\": [team_table[\"Home xG\"].mean()]\n",
    "        }\n",
    "        new_df = pd.DataFrame(new_data)\n",
    "        home_averages = pd.concat([home_averages, new_df], ignore_index=True)\n",
    "    \n",
    "    return away_averages, home_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73f417fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the squad names in lg_table more consistent with home_averages and away_averages\n",
    "def merge_lg_and_match_tables(lg_table, home_averages, away_averages):\n",
    "    \n",
    "    # Ensure consistent squad names\n",
    "    corrections = {\n",
    "        \"Nott'ham Forest\": \"Nottingham Forest\",\n",
    "        \"Wolves\": \"Wolverhampton Wanderers\",\n",
    "        \"Tottenham\": \"Tottenham Hotspur\",\n",
    "        \"Manchester Utd\": \"Manchester United\",\n",
    "        \"Newcastle Utd\": \"Newcastle United\",\n",
    "        \"Sheffield Utd\": \"Sheffield United\",\n",
    "        \"Brighton\": \"Brighton & Hove Albion\",\n",
    "        \"West Ham\": \"West Ham United\"\n",
    "    }\n",
    "    \n",
    "    lg_table[\"Squad\"] = lg_table[\"Squad\"].replace(corrections)\n",
    "    \n",
    "    #Merge the cleaned results from home_averages and away_averages with match_table\n",
    "    merged = pd.merge(lg_table, home_averages, on=\"Squad\", how=\"inner\")\n",
    "    merged = pd.merge(merged, away_averages, on=\"Squad\", how=\"inner\")\n",
    "    #merged = merged.drop(columns=[\"Last 5\"])\n",
    "    \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e907002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_stats(merged, home_atk_str, away_atk_str, home_def_str, away_def_str):\n",
    "    \n",
    "    team_stats = pd.DataFrame()\n",
    "\n",
    "    #Calculate squad home/away attacking strength for each squad\n",
    "    for squad in merged[\"Squad\"].unique():\n",
    "        team = merged[merged[\"Squad\"] == squad]\n",
    "\n",
    "        strengths = {\n",
    "        \"Squad\" : squad,\n",
    "        \"home_atk_str\" : team[\"Home xG\"]/home_atk_str,\n",
    "        \"away_atk_str\" : team[\"Away xG\"]/away_atk_str,\n",
    "        \"home_def_str\" : team[\"Home xGA\"]/home_def_str,\n",
    "        \"away_def_str\" : team[\"Away xGA\"]/away_def_str\n",
    "        }\n",
    "\n",
    "        team_stats = pd.concat([team_stats, pd.DataFrame(strengths)], ignore_index=True)\n",
    "    return team_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a2385a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve poisson distribution probabilities for home/away goals\n",
    "def compareTeams(home_team, away_team, stats, avg_home_xG, avg_away_xG):\n",
    "    \n",
    "    atk = stats[stats[\"Squad\"] == home_team][\"away_atk_str\"] \n",
    "    dfnce = stats[stats[\"Squad\"] == away_team][\"home_def_str\"]\n",
    "    result = float(atk) * float(dfnce) * float(avg_away_xG)\n",
    "    \n",
    "    home_probs = []\n",
    "    for i in range(0, 6):   \n",
    "        numbers = poisson.pmf(i, result)\n",
    "        home_probs.append(numbers)\n",
    "\n",
    "    \n",
    "    atk = stats[stats[\"Squad\"] == away_team][\"away_atk_str\"] \n",
    "    dfnce = stats[stats[\"Squad\"] == home_team][\"home_def_str\"]\n",
    "    \n",
    "    result = float(atk) * float(dfnce) * float(avg_away_xG)\n",
    "    \n",
    "    away_probs = []\n",
    "    for i in range(0, 6):   \n",
    "        numbers = poisson.pmf(i, result)\n",
    "        away_probs.append(numbers)\n",
    "        \n",
    "    return home_probs, away_probs\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2af3f46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create poisson probability distribution dataframe\n",
    "def getPoisson(home, away):\n",
    "    probs = pd.DataFrame(columns=[\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"])\n",
    "    for h in home:\n",
    "        home_goals = []\n",
    "        for a in away:\n",
    "            home_goals.append(round(h*a, 5))\n",
    "        probs.loc[len(probs)] = home_goals\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "92861ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum total probabilities for draw, home and away.\n",
    "def summarise(probs, home_squad, away_squad):\n",
    "    draw_probs = []\n",
    "    away_probs = []\n",
    "    home_probs = []\n",
    "    for i in range(0, 6):\n",
    "        draw_probs.append(probs.iloc[i, i])\n",
    "\n",
    "        for j in range(0, 6):\n",
    "            if(j > i):\n",
    "                away_probs.append(probs.iloc[i, j])\n",
    "            if(j < i):\n",
    "                home_probs.append(probs.iloc[i, j])\n",
    "\n",
    "    sum_draw_probs = round(sum(draw_probs), 2)\n",
    "    away_win_probs = round(sum(away_probs), 2)\n",
    "    home_win_probs = round(sum(home_probs), 2)\n",
    "    \n",
    "    # Define the statistics\n",
    "    home_win_percentage = home_win_probs * 100\n",
    "    away_win_percentage = away_win_probs * 100\n",
    "    draw_percentage = sum_draw_probs * 100\n",
    "    total_probability = sum_draw_probs + away_win_probs + home_win_probs\n",
    "\n",
    "    # Create a dictionary with the statistics\n",
    "    data = {\n",
    "        'Team': [home_squad, away_squad, 'Draw', 'Total'],\n",
    "        'Win Chance (%)': [home_win_percentage, away_win_percentage, draw_percentage, total_probability],\n",
    "        'Odds': [round(1/home_win_probs, 2), round(1/away_win_probs, 2), round(1/sum_draw_probs, 2), '-']\n",
    "    }\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Print the DataFrame\n",
    "    print(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1381640",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47e5158b-2a9b-41d3-bcfe-8ea44de24f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Link', 'Date', 'Stage', 'Home Team', 'Away Team', 'Home Goals',\n",
      "       'Away Goals', 'Home xG', 'Away xG', 'Shots'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(lg_table.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22eb0e6-19fa-4a44-b687-d8281dc6f063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105804a5-f0b6-4f20-9cc7-182db9cfa9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
